# Diagon Benchmark Report Template

This template defines the standard format for all benchmark reports generated by Diagon benchmark skills.

---

# Benchmark Report: [Benchmark Name]

**Report ID**: `[BENCHMARK_NAME]_[YYYYMMDD_HHMMSS]`
**Generated**: [YYYY-MM-DD HH:MM:SS]
**Diagon Version**: [commit hash or version]
**Benchmark Skill**: [skill name and version]

---

## Executive Summary

**Result**: [✅ PASS | ⚠️ PARTIAL | ❌ FAIL]

**Key Findings** (3-5 bullet points):
- [Most important finding #1]
- [Most important finding #2]
- [Most important finding #3]

**Performance vs Target**:
- Indexing: [Above/At/Below target]
- Query latency: [X]x faster/slower than Lucene
- Index size: [Comparable/Larger/Smaller] than Lucene

**Critical Issues**: [None | List any critical issues]

---

## Test Environment

### Hardware
- **CPU**: [Model, cores, frequency]
- **RAM**: [Amount, type]
- **Storage**: [Type: SSD/HDD, capacity]
- **OS**: [Distribution, version, kernel]

### Software
- **Compiler**: [GCC/Clang version]
- **Build Type**: Release (no LTO)
- **Optimization**: `-O3 -march=native`
- **Diagon Commit**: [git commit hash]
- **Build Date**: [YYYY-MM-DD HH:MM:SS]

### Dataset
- **Name**: [e.g., Reuters-21578]
- **Documents**: [count]
- **Total Size**: [MB/GB]
- **Source**: [path or URL]
- **Verified**: ✅ Yes | ❌ No

---

## Indexing Performance

### Results

| Metric | Value | Target | Status |
|--------|-------|--------|--------|
| Documents Indexed | [count] | [count] | [✅/❌] |
| Time (seconds) | [value] | [value] | [✅/⚠️/❌] |
| Throughput (docs/sec) | [value] | ≥[target] | [✅/⚠️/❌] |
| Index Size (MB) | [value] | [range] | [✅/⚠️/❌] |
| Storage (bytes/doc) | [value] | [range] | [✅/⚠️/❌] |

### Comparison with Lucene

| Metric | Diagon | Lucene | Ratio | Status |
|--------|--------|--------|-------|--------|
| Throughput (docs/sec) | [value] | [value] | [X.XX]x | [✅/⚠️/❌] |
| Index Size (MB) | [value] | [value] | [X.XX]x | [✅/⚠️/❌] |
| Time (seconds) | [value] | [value] | [X.XX]x | [✅/⚠️/❌] |

**Analysis**:
- [Brief explanation of indexing performance]
- [Comparison with Lucene]
- [Any anomalies or issues]

---

## Query Performance

### Single-Term Queries

| Query | Hits | P50 (μs) | P95 (μs) | P99 (μs) | vs Lucene | Status |
|-------|------|----------|----------|----------|-----------|--------|
| [term1] | [n] | [value] | [value] | [value] | [X.X]x faster/slower | [✅/⚠️/❌] |
| [term2] | [n] | [value] | [value] | [value] | [X.X]x faster/slower | [✅/⚠️/❌] |
| [term3] | [n] | [value] | [value] | [value] | [X.X]x faster/slower | [✅/⚠️/❌] |

**Target**: 3-5x faster than Lucene

### Boolean AND Queries

| Query | Hits | P50 (μs) | P95 (μs) | P99 (μs) | vs Lucene | Status |
|-------|------|----------|----------|----------|-----------|--------|
| [term1 AND term2] | [n] | [value] | [value] | [value] | [X.X]x faster/slower | [✅/⚠️/❌] |

**Target**: 3-5x faster than Lucene

### Boolean OR Queries

| Query | Hits | P50 (μs) | P95 (μs) | P99 (μs) | vs Lucene | Status |
|-------|------|----------|----------|----------|-----------|--------|
| [term1 OR term2] | [n] | [value] | [value] | [value] | [X.X]x faster/slower | [✅/⚠️/❌] |
| [5-term OR query] | [n] | [value] | [value] | [value] | [X.X]x faster/slower | [✅/⚠️/❌] |

**Target**: 3-5x faster than Lucene

### Query Performance Summary

| Query Type | Average Speedup | Min Speedup | Max Speedup | Target Met |
|------------|-----------------|-------------|-------------|------------|
| Single-term | [X.X]x | [X.X]x | [X.X]x | [✅/❌] |
| Boolean AND | [X.X]x | [X.X]x | [X.X]x | [✅/❌] |
| Boolean OR | [X.X]x | [X.X]x | [X.X]x | [✅/❌] |
| **Overall** | **[X.X]x** | **[X.X]x** | **[X.X]x** | **[✅/❌]** |

---

## Performance Analysis

### Strengths ✅
1. [What performed well]
2. [Where we exceeded expectations]
3. [Positive findings]

### Areas for Improvement ⚠️
1. [What could be better]
2. [Where we fell short of targets]
3. [Performance concerns]

### Critical Issues ❌
[None | List critical issues that must be addressed]

---

## Detailed Comparison with Lucene

### Head-to-Head Performance

**Indexing**:
- Throughput: Diagon is [X.X]x [faster/slower] than Lucene
- Index size: Diagon index is [X.X]x [larger/smaller] than Lucene
- **Assessment**: [✅ Competitive | ⚠️ Acceptable | ❌ Needs improvement]

**Query Latency**:
- Average speedup: [X.X]x [faster/slower]
- Best case: [X.X]x faster on [query type]
- Worst case: [X.X]x [faster/slower] on [query type]
- **Assessment**: [✅ Target met (3-10x) | ⚠️ Below target | ❌ Slower than Lucene]

**Index Size**:
- Size comparison: [similar | larger | smaller]
- Compression ratio: [comparable | better | worse]
- **Assessment**: [✅ Competitive | ⚠️ Acceptable | ❌ Needs improvement]

### Target Achievement

| Goal | Target | Achieved | Status |
|------|--------|----------|--------|
| Search speed vs Lucene | 3-10x faster | [X.X]x | [✅/⚠️/❌] |
| Indexing throughput | ≥5K docs/sec | [value] | [✅/⚠️/❌] |
| Index size | Competitive | [X.X]x Lucene | [✅/⚠️/❌] |
| Query correctness | 100% | [XX]% | [✅/❌] |

---

## Issues and Concerns

### Critical (Must Fix) ❌
[None | List with details]

### Important (Should Fix) ⚠️
[None | List with details]

### Minor (Nice to Fix) ℹ️
[None | List with details]

---

## Recommendations

### Immediate Actions
1. [Action item #1]
2. [Action item #2]

### Short-term Improvements
1. [Improvement #1]
2. [Improvement #2]

### Long-term Optimizations
1. [Optimization #1]
2. [Optimization #2]

---

## Raw Data

### Indexing Details
```
[Raw indexing output or logs]
```

### Query Results (Full Data)
```
[Complete query benchmark results]
```

### Build Information
```
[Compiler output, build flags, library versions]
```

### System Information
```
[CPU info, memory info, disk info]
```

---

## Reproducibility

### Build Commands
```bash
[Exact commands to reproduce build]
```

### Benchmark Commands
```bash
[Exact commands to reproduce benchmark]
```

### Dataset Setup
```bash
[Commands to setup dataset]
```

---

## Appendix

### Glossary
- **P50/P95/P99**: 50th/95th/99th percentile latency
- **Throughput**: Documents indexed per second
- **Speedup**: Performance ratio vs baseline (Lucene)

### References
- Lucene benchmark: [URL or path]
- Dataset info: [URL or documentation]
- Diagon commit: [GitHub URL]

---

**Report Generated By**: Diagon Benchmark Framework
**Template Version**: 1.0.0
**Contact**: [Project contact info]

---

## Signature

**Reviewed By**: [Name/Role]
**Date**: [YYYY-MM-DD]
**Approval**: [✅ Approved | ⚠️ Conditional | ❌ Rejected]

---

*This report follows the Diagon project tenets: Be Self-discipline, Be Humble and Straight, Be Honest, Be Rational, Insist Highest Standard.*
