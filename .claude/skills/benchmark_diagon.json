{
  "name": "benchmark_diagon",
  "description": "Run pure Diagon performance benchmark on Reuters-21578 dataset",
  "version": "1.0.0",
  "arguments": [
    {
      "name": "benchmark",
      "description": "Which benchmark to run: reuters (standard), wand (WAND optimization), or both (default: reuters)",
      "type": "string",
      "default": "reuters"
    },
    {
      "name": "build",
      "description": "Build the benchmark before running (default: true)",
      "type": "boolean",
      "default": true
    },
    {
      "name": "clean_index",
      "description": "Clean existing index before benchmarking (default: true)",
      "type": "boolean",
      "default": true
    },
    {
      "name": "save_results",
      "description": "Save results to timestamped file (default: true)",
      "type": "boolean",
      "default": true
    },
    {
      "name": "compare_baseline",
      "description": "Compare with previous baseline if available (default: true)",
      "type": "boolean",
      "default": true
    }
  ],
  "prompt": "You are executing the Diagon performance benchmark on the Reuters-21578 dataset.\n\n## Your Task\n\nRun Diagon performance benchmark with these parameters:\n- Benchmark type: {{benchmark}}\n- Build first: {{build}}\n- Clean index: {{clean_index}}\n- Save results: {{save_results}}\n- Compare baseline: {{compare_baseline}}\n\n## About This Benchmark\n\nThis benchmark focuses on **pure Diagon performance** (not comparison with Lucene):\n- **Purpose**: Measure Diagon's absolute performance\n- **Use**: Track performance over time, detect regressions\n- **Dataset**: Reuters-21578 (21,578 news articles from 1987)\n- **Location**: `/home/ubuntu/opensearch_warmroom/lucene/lucene/benchmark/work/reuters-out/`\n- **Baseline**: Compare with previous Diagon runs (not Lucene)\n\n## Difference from /benchmark_reuters_lucene\n\n| Aspect | /benchmark_diagon | /benchmark_reuters_lucene |\n|--------|-------------------|---------------------------|\n| Focus | Pure Diagon performance | Diagon vs Lucene comparison |\n| Baseline | Previous Diagon runs | Apache Lucene |\n| Goal | Track trends, detect regressions | Meet 3-10x faster target |\n| Report emphasis | Absolute metrics, trends | Relative speedup vs Lucene |\n| Use case | Daily performance tracking | Milestone validation |\n\n## Available Benchmarks\n\n### 1. ReutersBenchmark (Standard)\n**Executable**: `ReutersBenchmark`\n**Tests**:\n- Indexing performance (21,578 documents)\n- Single-term queries (dollar, oil, trade)\n- Boolean AND queries (oil AND price)\n- Boolean OR queries (2-term and 5-term)\n- Reports: throughput, latency, index size\n\n### 2. ReutersWANDBenchmark (WAND Optimization)\n**Executable**: `ReutersWANDBenchmark`\n**Tests**:\n- WAND (Weak AND) early termination\n- Block-max scoring optimization\n- Uses Google Benchmark framework\n- Detailed performance metrics\n\n### 3. Both (Run All)\nRuns both benchmarks sequentially for comprehensive results.\n\n## Execution Procedure\n\n### Step 1: Build Benchmarks (if build=true)\n\n```bash\ncd /home/ubuntu/diagon\n\n# Build the requested benchmark(s)\nif [[ \"{{benchmark}}\" == \"reuters\" || \"{{benchmark}}\" == \"both\" ]]; then\n    cd build\n    make ReutersBenchmark -j8\nfi\n\nif [[ \"{{benchmark}}\" == \"wand\" || \"{{benchmark}}\" == \"both\" ]]; then\n    cd build\n    make ReutersWANDBenchmark -j8\nfi\n```\n\nIf build directory doesn't exist, inform the user they need to run `/build_diagon target=benchmarks` first.\n\n### Step 2: Load Previous Baseline (if compare_baseline=true)\n\n```bash\n# Look for most recent baseline\nBASELINE_DIR=\"/home/ubuntu/diagon/benchmark_results\"\nif [ -f \"$BASELINE_DIR/diagon_baseline.json\" ]; then\n    echo \"Loading baseline from: $BASELINE_DIR/diagon_baseline.json\"\n    # Parse baseline metrics for comparison\nelse\n    echo \"No baseline found - this run will become the baseline\"\nfi\n```\n\n### Step 3: Clean Index (if clean_index=true)\n\n```bash\n# Remove old index\nrm -rf /tmp/diagon_reuters_index\n```\n\nThis ensures a fresh benchmark without cached data.\n\n### Step 4: Verify Dataset Exists\n\n```bash\nls /home/ubuntu/opensearch_warmroom/lucene/lucene/benchmark/work/reuters-out/*.txt | head -5\n```\n\nIf dataset not found, report error and suggest downloading it.\n\n### Step 5: Run Benchmark(s)\n\n**For benchmark='reuters':**\n```bash\ncd /home/ubuntu/diagon/build/benchmarks\n./ReutersBenchmark\n```\n\n**For benchmark='wand':**\n```bash\ncd /home/ubuntu/diagon/build/benchmarks\n./ReutersWANDBenchmark\n```\n\n**For benchmark='both':**\n```bash\ncd /home/ubuntu/diagon/build/benchmarks\necho \"========================================\"\necho \"Running Standard Diagon Benchmark\"\necho \"========================================\"\n./ReutersBenchmark\n\necho \"\"\necho \"========================================\"\necho \"Running WAND Diagon Benchmark\"\necho \"========================================\"\n./ReutersWANDBenchmark\n```\n\n### Step 6: Compare with Baseline (if compare_baseline=true)\n\nAfter running benchmark, compare key metrics with baseline:\n\n```bash\n# Compare indexing throughput\nCURRENT_THROUGHPUT=[value]\nBASELINE_THROUGHPUT=[baseline_value]\nDELTA=$((CURRENT_THROUGHPUT - BASELINE_THROUGHPUT))\n\nif [ $DELTA -lt -500 ]; then\n    echo \"⚠️ REGRESSION: Throughput decreased by $DELTA docs/sec\"\nelif [ $DELTA -gt 500 ]; then\n    echo \"✅ IMPROVEMENT: Throughput increased by $DELTA docs/sec\"\nelse\n    echo \"✅ STABLE: Throughput change: $DELTA docs/sec (within threshold)\"\nfi\n\n# Similar comparisons for query latencies\n```\n\n### Step 7: Generate Report Following Template\n\n**CRITICAL**: Follow the benchmark report template at `.claude/BENCHMARK_REPORT_TEMPLATE_V2.md`\n\nGenerate a complete report including:\n\n**Report Template Requirements**:\nRead `.claude/BENCHMARK_REPORT_TEMPLATE_V2.md` and follow it exactly. The report MUST include:\n\n1. **Executive Summary** (Required)\n   - Overall result: ✅ PASS | ⚠️ PARTIAL | ❌ FAIL\n   - 3-5 key findings (bullet points)\n   - Performance vs baseline summary (if available)\n   - Performance vs targets summary\n   - Critical issues (if any)\n\n2. **Test Environment** (Required)\n   - Hardware, software, dataset details\n   - Diagon commit hash\n   - Build configuration\n   - Verification commands\n\n3. **Indexing Performance** (Required)\n   - Table with: docs indexed, time, throughput, index size\n   - Comparison with baseline (if available)\n   - Comparison with targets\n   - Status indicators (✅/⚠️/❌)\n\n4. **Query Performance** (Required)\n   - Separate tables for: single-term, AND, OR queries\n   - P50, P95, P99 latencies\n   - Hits count\n   - vs Baseline comparison (if available)\n   - vs Targets comparison\n   - Overall summary table\n\n5. **Performance Analysis** (Required)\n   - Strengths ✅ (what went well)\n   - Areas for Improvement ⚠️ (what fell short)\n   - Critical Issues ❌ (must-fix problems)\n   - Trend analysis (improving/stable/regressing)\n\n6. **Detailed Comparison** (Required)\n   - Head-to-head with baseline (if available)\n   - Target achievement table\n   - Regression detection\n   - Performance trends\n\n7. **Issues and Concerns** (Required)\n   - Critical (must fix) ❌\n   - Important (should fix) ⚠️\n   - Minor (nice to fix) ℹ️\n   - Use \"None\" if no issues (don't skip)\n\n8. **Recommendations** (Required)\n   - Immediate actions\n   - Short-term improvements\n   - Long-term optimizations\n\n9. **Raw Data** (Required)\n   - Complete indexing output\n   - Full query results\n   - Build information\n   - System information\n\n10. **Reproducibility** (Required)\n    - Exact build commands\n    - Exact benchmark commands\n    - Dataset setup instructions\n\n**Report Format**:\n- Use Markdown format\n- Save to: `/home/ubuntu/diagon/benchmark_results/diagon_[YYYYMMDD_HHMMSS].md`\n- Display console summary + full report path\n- Follow template structure exactly\n\n**Performance Targets** (from CLAUDE.md):\n- **Indexing throughput**: ≥5,000 docs/sec\n- **Query latency**: Single-term <1ms, AND <2ms, OR <5ms\n- **Index size**: 10-15 MB for Reuters-21578\n- **Storage efficiency**: 250-700 bytes/doc\n- **Memory efficiency**: Track peak usage\n\n**Regression Detection**:\nIf comparing with baseline:\n- **Regression**: ❌ >10% slower than baseline\n- **Stable**: ✅ Within ±10% of baseline\n- **Improvement**: ✅ >10% faster than baseline\n\n**Critical Reminders from CLAUDE.md**:\n- \"Be Honest\": Report actual numbers, not predicted - annotate clearly\n- \"Be Humble and Straight\": Don't bury issues - list them directly\n- \"Be Rational\": Base findings on observations, not guesses\n- \"Insist Highest Standard\": Track performance trends, no regressions\n- If regression detected: mark ❌ CRITICAL and investigate immediately\n\n### Step 8: Save as Baseline (if save_results=true)\n\nSave key metrics as new baseline for future comparisons:\n\n```bash\n# Save baseline metrics\nBASELINE_FILE=\"/home/ubuntu/diagon/benchmark_results/diagon_baseline.json\"\ncat > \"$BASELINE_FILE\" <<EOF\n{\n  \"timestamp\": \"$(date -Iseconds)\",\n  \"commit\": \"$(git rev-parse --short HEAD)\",\n  \"indexing\": {\n    \"throughput\": [value],\n    \"time\": [value],\n    \"index_size\": [value]\n  },\n  \"queries\": {\n    \"single_term_p99\": [value],\n    \"boolean_and_p99\": [value],\n    \"boolean_or_p99\": [value]\n  }\n}\nEOF\n\necho \"Baseline saved to: $BASELINE_FILE\"\n```\n\n## Error Handling\n\n### Build Directory Missing\n```\n❌ Build directory not found!\nRun: /build_diagon target=benchmarks\n```\n\n### Benchmark Executable Missing\n```\n❌ Benchmark executable not found!\nRun: /build_diagon target=benchmarks\nThen: make ReutersBenchmark\n```\n\n### Dataset Missing\n```\n❌ Reuters dataset not found!\nExpected: /home/ubuntu/opensearch_warmroom/lucene/lucene/benchmark/work/reuters-out/\n\nTo download:\n1. cd /home/ubuntu/opensearch_warmroom/lucene/lucene/benchmark\n2. ant get-reuters\n3. Verify: ls work/reuters-out/*.txt | wc -l\n   Should show: 21578\n```\n\n### Benchmark Crashes\n- Check if ICU is linked: `ldd build/benchmarks/ReutersBenchmark | grep icu`\n- Try rebuilding: `/build_diagon target=benchmarks`\n- Check logs for specific errors\n\n### Regression Detected\n```\n⚠️ PERFORMANCE REGRESSION DETECTED!\n\nMetric: [metric name]\nBaseline: [baseline value]\nCurrent: [current value]\nDelta: [delta] ([XX]% slower)\n\nAction required:\n1. Review recent code changes\n2. Profile to identify bottleneck\n3. Create issue ticket\n4. Investigate root cause\n```\n\n## Performance Expectations\n\n### Indexing (21,578 documents)\n- **Target throughput**: ≥5,000 docs/sec\n- **Target time**: 2-5 seconds\n- **Regression threshold**: >10% slower than baseline\n\n### Query Latency (P99)\n- **Single term**: <1ms (1,000 μs)\n- **Boolean AND**: <2ms (2,000 μs)\n- **Boolean OR (2-term)**: <3ms (3,000 μs)\n- **Boolean OR (5-term)**: <5ms (5,000 μs)\n- **Regression threshold**: >10% slower than baseline\n\n### Index Size\n- **Expected**: 10-15 MB\n- **Per doc**: 250-700 bytes/doc\n- **Regression threshold**: >20% larger than baseline\n\n## Success Criteria\n\nA successful benchmark run must:\n- ✅ Index all 21,578 documents without errors\n- ✅ Complete all test queries successfully\n- ✅ Report reasonable performance numbers\n- ✅ Show no crashes or undefined behavior\n- ✅ Generate complete report following template\n- ✅ No performance regressions vs baseline (if available)\n- ✅ Meet absolute performance targets\n\n## Use Cases\n\n### Daily Performance Tracking\n- Run: `/benchmark_diagon` daily\n- Compare: With previous baseline\n- Detect: Regressions early\n- Track: Performance trends over time\n\n### Pre-commit Validation\n- Run: Before major commits\n- Ensure: No performance regressions\n- Verify: Changes don't slow down system\n\n### Release Validation\n- Run: Before each release\n- Compare: With previous release\n- Ensure: Performance improvements or stability\n- Document: Performance changes in release notes\n\n### Performance Optimization\n- Run: Before and after optimization\n- Measure: Actual improvement\n- Validate: Optimization effectiveness\n- Document: Performance gains\n\nNow execute the Diagon benchmark following these steps."
}
