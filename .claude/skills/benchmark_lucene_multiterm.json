{
  "name": "benchmark_lucene_multiterm",
  "description": "Benchmark Diagon vs Lucene multi-term query performance comparison",
  "version": "1.0.0",
  "arguments": [
    {
      "name": "query_type",
      "description": "Query type to test: and (Boolean AND), or (Boolean OR), mixed (AND+OR), or all (default: all)",
      "type": "string",
      "default": "all"
    },
    {
      "name": "term_counts",
      "description": "Term counts to test: small (2-3 terms), medium (4-5 terms), large (6-10 terms), or all (default: all)",
      "type": "string",
      "default": "all"
    },
    {
      "name": "build",
      "description": "Build the benchmark before running (default: true)",
      "type": "boolean",
      "default": true
    },
    {
      "name": "iterations",
      "description": "Number of iterations per query for stable measurements (default: 100)",
      "type": "number",
      "default": 100
    },
    {
      "name": "save_results",
      "description": "Save results to timestamped file (default: true)",
      "type": "boolean",
      "default": true
    },
    {
      "name": "target_speedup",
      "description": "Target speedup vs Lucene (default: 3.0x minimum)",
      "type": "number",
      "default": 3.0
    }
  ],
  "prompt": "You are executing a focused multi-term query comparison benchmark between Diagon and Lucene.\n\n## Your Task\n\nCompare Diagon vs Lucene multi-term query performance with these parameters:\n- Query type: {{query_type}}\n- Term counts: {{term_counts}}\n- Build first: {{build}}\n- Iterations: {{iterations}}\n- Save results: {{save_results}}\n- Target speedup: {{target_speedup}}x\n\n## About This Benchmark\n\n**Focus**: Multi-term query performance comparison (Diagon vs Lucene)\n**Purpose**: Validate 3-10x speedup target for multi-term queries specifically\n**Dataset**: Reuters-21578 (21,578 documents)\n**Specialization**: Deep dive into Boolean operators and term count scaling\n\n### Why Multi-Term Query Comparison?\n\nMulti-term queries are:\n- **Most common**: Real-world queries often have 2-5 terms\n- **Most complex**: Require intersection/union operations\n- **Performance-critical**: Can be 10-100x slower than single-term\n- **Optimization target**: Where Diagon can demonstrate advantage\n- **WAND showcase**: Early termination most valuable for OR queries\n\n### Comparison Strategy\n\n**For Diagon**:\n- Run multi-term queries with various term counts\n- Measure P50/P95/P99 latencies\n- Track WAND effectiveness (for OR queries)\n- Profile memory usage and cache behavior\n\n**For Lucene** (baseline):\n- Use known Lucene multi-term query performance data\n- OR use benchmark results from Lucene's own benchmarks\n- Compare with Diagon on same queries\n\n**Calculate Speedup**:\n- Speedup = Lucene_latency / Diagon_latency\n- Report per query type and term count\n- Validate against {{target_speedup}}x minimum\n\n## Query Test Matrix\n\n### Boolean AND Queries (Intersection)\n\n**2-term AND**:\n- `oil AND price` (high frequency both)\n- `trade AND export` (medium frequency)\n- `economic AND policy` (lower frequency)\n\n**3-term AND**:\n- `oil AND price AND market`\n- `trade AND export AND agreement`\n- `economic AND policy AND government`\n\n**5-term AND**:\n- `oil AND price AND market AND crude AND barrel`\n- `trade AND export AND import AND deficit AND surplus`\n\n**10-term AND** (stress test):\n- `oil AND price AND market AND crude AND barrel AND production AND opec AND energy AND petroleum AND industry`\n\n### Boolean OR Queries (Union)\n\n**2-term OR**:\n- `oil OR petroleum` (similar terms)\n- `dollar OR currency` (related terms)\n- `trade OR export` (related concepts)\n\n**3-term OR**:\n- `oil OR petroleum OR energy`\n- `dollar OR currency OR exchange`\n- `trade OR export OR import`\n\n**5-term OR**:\n- `oil OR trade OR market OR price OR dollar`\n- `bank OR financial OR credit OR loan OR mortgage`\n- `stock OR share OR equity OR trading OR investor`\n\n**10-term OR** (WAND stress test):\n- `oil OR trade OR market OR price OR dollar OR economy OR bank OR stock OR government OR company`\n\n### Mixed Boolean Queries\n\n**AND with OR** (nested):\n- `(oil OR petroleum) AND (price OR cost)`\n- `(trade OR export) AND (deficit OR surplus)`\n- `(bank OR financial) AND (crisis OR problem)`\n\n**OR with AND** (nested):\n- `(oil AND price) OR (trade AND deficit)`\n- `(dollar AND exchange) OR (currency AND rate)`\n\n**Complex nested**:\n- `(oil OR petroleum) AND (price OR cost) AND market`\n- `((trade OR export) AND deficit) OR ((import OR goods) AND surplus)`\n\n## Performance Targets\n\n### Target Speedup (Diagon vs Lucene)\n\n**Boolean AND Queries** (minimum speedup):\n- **2-term**: ≥{{target_speedup}}x faster\n- **3-term**: ≥{{target_speedup}}x faster\n- **5-term**: ≥3.5x faster (more complex)\n- **10-term**: ≥4.0x faster (highest complexity)\n\n**Boolean OR Queries** (WAND advantage):\n- **2-term**: ≥3.5x faster\n- **3-term**: ≥4.0x faster\n- **5-term**: ≥5.0x faster (WAND shines)\n- **10-term**: ≥6.0x faster (maximum WAND benefit)\n\n**Mixed Queries**:\n- **Simple mixed**: ≥{{target_speedup}}x faster\n- **Complex mixed**: ≥4.0x faster\n\n### Absolute Performance Targets (Diagon P99 latency)\n\n**Boolean AND**:\n- 2-term: <2ms, 3-term: <3ms, 5-term: <5ms, 10-term: <10ms\n\n**Boolean OR**:\n- 2-term: <3ms, 3-term: <5ms, 5-term: <8ms, 10-term: <15ms\n\n**Mixed**:\n- Simple: <5ms, Complex: <10ms\n\n## Execution Procedure\n\n### Step 1: Build Benchmarks (if build=true)\n\n```bash\ncd /home/ubuntu/diagon/build\n\n# Build Diagon benchmark\nmake ReutersBenchmark -j8\n\n# Note: Lucene benchmark uses pre-existing results or separate run\n```\n\n### Step 2: Prepare Query Sets\n\nGenerate query sets based on {{query_type}} and {{term_counts}}:\n\n```python\nquery_set = []\n\nif query_type in ['and', 'all']:\n    if term_counts in ['small', 'all']:\n        query_set.extend([\n            \"oil AND price\",\n            \"trade AND export\",\n            \"economic AND policy\",\n            \"oil AND price AND market\",\n            \"trade AND export AND agreement\",\n            \"economic AND policy AND government\"\n        ])\n    if term_counts in ['medium', 'all']:\n        query_set.extend([\n            \"oil AND price AND market AND crude AND barrel\",\n            \"trade AND export AND import AND deficit AND surplus\"\n        ])\n    if term_counts in ['large', 'all']:\n        query_set.extend([\n            \"oil AND price AND market AND crude AND barrel AND production AND opec AND energy AND petroleum AND industry\"\n        ])\n\nif query_type in ['or', 'all']:\n    if term_counts in ['small', 'all']:\n        query_set.extend([\n            \"oil OR petroleum\",\n            \"dollar OR currency\",\n            \"trade OR export\",\n            \"oil OR petroleum OR energy\",\n            \"dollar OR currency OR exchange\",\n            \"trade OR export OR import\"\n        ])\n    if term_counts in ['medium', 'all']:\n        query_set.extend([\n            \"oil OR trade OR market OR price OR dollar\",\n            \"bank OR financial OR credit OR loan OR mortgage\"\n        ])\n    if term_counts in ['large', 'all']:\n        query_set.extend([\n            \"oil OR trade OR market OR price OR dollar OR economy OR bank OR stock OR government OR company\"\n        ])\n\nif query_type in ['mixed', 'all']:\n    query_set.extend([\n        \"(oil OR petroleum) AND (price OR cost)\",\n        \"(trade OR export) AND (deficit OR surplus)\",\n        \"(oil AND price) OR (trade AND deficit)\",\n        \"(oil OR petroleum) AND (price OR cost) AND market\"\n    ])\n```\n\n### Step 3: Index Reuters Dataset\n\n```bash\n# Clean and index\nrm -rf /tmp/diagon_reuters_index\ncd /home/ubuntu/diagon/build/benchmarks\n\n# Run indexing (most benchmarks do this automatically)\n```\n\n### Step 4: Run Diagon Multi-Term Queries\n\n```bash\necho \"====================================\"\necho \"Running Diagon Multi-Term Queries\"\necho \"====================================\"\n\nfor query in \"${QUERY_SET[@]}\"; do\n    echo \"\"\n    echo \"Query: $query\"\n    echo \"  Term count: $(echo $query | tr -cd ' ' | wc -c)++\"\n    echo \"  Type: $QUERY_TYPE\"\n    echo \"  Iterations: {{iterations}}\"\n    \n    # Run benchmark and capture metrics\n    # P50, P95, P99 latencies, hit count, memory usage\n    \n    echo \"  Diagon P50: $DIAGON_P50_US μs\"\n    echo \"  Diagon P95: $DIAGON_P95_US μs\"\n    echo \"  Diagon P99: $DIAGON_P99_US μs\"\n    echo \"  Hits: $HIT_COUNT\"\ndone\n```\n\n### Step 5: Get Lucene Baseline Data\n\n**Option A: Use Known Lucene Benchmarks**\n```bash\n# Lucene baseline data from published benchmarks or previous runs\n# Typical Lucene multi-term query performance (Reuters-21578):\n#   2-term AND: ~6-8ms (P99)\n#   3-term AND: ~10-12ms (P99)\n#   5-term AND: ~20-25ms (P99)\n#   2-term OR: ~15-20ms (P99)\n#   5-term OR: ~50-80ms (P99, without WAND)\n```\n\n**Option B: Run Lucene Benchmark** (if available)\n```bash\ncd /home/ubuntu/opensearch_warmroom/lucene/lucene/benchmark\n\n# Create multi-term query benchmark config\ncat > conf/multiterm_queries.alg <<'EOF'\nanalyzer=org.apache.lucene.analysis.standard.StandardAnalyzer\ndirectory=FSDirectory\ndocs.dir=work/reuters21578\n\n{ \"MultiTermQueries\"\n    OpenReader\n    { \"AND2\" Search(\"oil AND price\") > : 1000\n    { \"AND3\" Search(\"oil AND price AND market\") > : 1000\n    { \"OR2\" Search(\"oil OR petroleum\") > : 1000\n    { \"OR5\" Search(\"oil OR trade OR market OR price OR dollar\") > : 1000\n    CloseReader\n    RepSumByName\n}\nEOF\n\n# Run benchmark\njava -Xmx4g -jar build/libs/lucene-benchmark.jar conf/multiterm_queries.alg > lucene_multiterm_results.txt\n```\n\n### Step 6: Calculate Speedup\n\nFor each query:\n\n```python\nspeedup = lucene_latency_p99_us / diagon_latency_p99_us\n\nif speedup >= target_speedup:\n    status = \"✅ PASS\"\nelif speedup >= target_speedup * 0.8:\n    status = \"⚠️ PARTIAL\"\nelse:\n    status = \"❌ FAIL\"\n\nprint(f\"Query: {query}\")\nprint(f\"  Lucene P99: {lucene_p99_us} μs\")\nprint(f\"  Diagon P99: {diagon_p99_us} μs\")\nprint(f\"  Speedup: {speedup:.2f}x\")\nprint(f\"  Target: {target_speedup}x\")\nprint(f\"  Status: {status}\")\n```\n\n### Step 7: Analyze Results\n\n**Scalability Analysis**:\n```\n# Check speedup vs term count\n# Expected: Speedup should increase with term count (especially for OR queries)\n# Diagon's WAND should provide greater advantage as term count increases\n```\n\n**WAND Effectiveness** (for OR queries):\n```\n# Compare OR query speedup vs AND query speedup\n# Expected: OR queries should have higher speedup due to WAND early termination\n# Lucene doesn't have block-max WAND, so this is Diagon's key advantage\n```\n\n**Frequency Impact**:\n```\n# Compare high-freq vs low-freq term queries\n# High-freq OR queries should show maximum speedup\n```\n\n### Step 8: Generate Comparison Report\n\n**CRITICAL**: Follow `.claude/BENCHMARK_REPORT_TEMPLATE_V2.md`\n\nReport MUST include:\n\n**1. Executive Summary**:\n- Overall result (PASS/PARTIAL/FAIL)\n- Key findings for multi-term comparison\n- Speedup achieved vs target\n- Best performing query types\n- Areas needing improvement\n\n**2. Test Environment**:\n- Standard environment details\n- Both Diagon and Lucene configurations\n- Dataset details\n\n**3. Multi-Term Query Comparison** (Enhanced section):\n\n**Boolean AND Comparison**:\n| Term Count | Sample Query | Lucene P99 | Diagon P99 | Speedup | Target | Status |\n|------------|--------------|------------|------------|---------|--------|--------|\n| 2 | oil AND price | [val] μs | [val] μs | [x.xx]x | {{target_speedup}}x | [✅/❌] |\n| 3 | oil AND price AND market | [val] μs | [val] μs | [x.xx]x | {{target_speedup}}x | [✅/❌] |\n| 5 | [5-term query] | [val] μs | [val] μs | [x.xx]x | 3.5x | [✅/❌] |\n| 10 | [10-term query] | [val] μs | [val] μs | [x.xx]x | 4.0x | [✅/❌] |\n\n**Boolean OR Comparison**:\n| Term Count | Sample Query | Lucene P99 | Diagon P99 | Speedup | Target | Status |\n|------------|--------------|------------|------------|---------|--------|--------|\n| 2 | oil OR petroleum | [val] μs | [val] μs | [x.xx]x | 3.5x | [✅/❌] |\n| 3 | oil OR petroleum OR energy | [val] μs | [val] μs | [x.xx]x | 4.0x | [✅/❌] |\n| 5 | [5-term OR] | [val] μs | [val] μs | [x.xx]x | 5.0x | [✅/❌] |\n| 10 | [10-term OR] | [val] μs | [val] μs | [x.xx]x | 6.0x | [✅/❌] |\n\n**Mixed Boolean Comparison**:\n| Query Type | Sample Query | Lucene P99 | Diagon P99 | Speedup | Target | Status |\n|------------|--------------|------------|------------|---------|--------|--------|\n| AND+OR | (oil OR petroleum) AND price | [val] μs | [val] μs | [x.xx]x | {{target_speedup}}x | [✅/❌] |\n| Complex | [complex query] | [val] μs | [val] μs | [x.xx]x | 4.0x | [✅/❌] |\n\n**4. Speedup Analysis**:\n\n**Speedup vs Term Count**:\n```\n# Graph or table showing speedup increasing with term count\n# Expected pattern:\n#   AND queries: Linear or sub-linear speedup increase\n#   OR queries: Super-linear speedup increase (WAND benefit)\n```\n\n**WAND Advantage**:\n```\n# Compare OR vs AND speedup\n# Calculate: OR_speedup / AND_speedup\n# Expected: >1.2x additional benefit for OR queries\n```\n\n**Overall Statistics**:\n```\n- Average speedup (all queries): [x.xx]x\n- Minimum speedup: [x.xx]x ([query])\n- Maximum speedup: [x.xx]x ([query])\n- Queries meeting target: [n]/[total] ([pct]%)\n```\n\n**5. Performance Analysis**:\n- Which query types meet speedup targets?\n- Which query types exceed expectations?\n- Which need optimization?\n- WAND working as expected?\n- Scalability trends positive?\n\n**6. Detailed Comparison**:\n- Compare with {{target_speedup}}x target\n- Identify gaps where speedup is below target\n- Analyze why certain queries don't meet target\n- Compare with absolute performance targets\n\n**7-10**: Standard report sections (Issues, Recommendations, Raw Data, Reproducibility)\n\n**Report Format**:\n- Save to: `/home/ubuntu/diagon/benchmark_results/lucene_multiterm_[YYYYMMDD_HHMMSS].md`\n- Follow template structure exactly\n\n## Key Metrics to Report\n\n### Comparison Metrics\n1. **Speedup ratio**: Lucene_latency / Diagon_latency\n2. **Speedup vs target**: Actual vs {{target_speedup}}x minimum\n3. **Speedup trend**: By term count (linear, sub-linear, super-linear)\n4. **WAND advantage**: OR speedup vs AND speedup\n5. **Consistency**: Variance in speedup across similar queries\n\n### Performance Metrics (both systems)\n1. **Latency by term count**: P50/P95/P99\n2. **Latency by query type**: AND vs OR vs mixed\n3. **Hit counts**: Verify correctness\n4. **Memory usage**: Peak memory during query\n\n### Quality Metrics\n1. **Correctness**: Hit counts match between systems\n2. **Stability**: Low variance across iterations\n3. **Target achievement**: % of queries meeting {{target_speedup}}x\n\n## Success Criteria\n\nA successful multi-term comparison benchmark must:\n- ✅ All term counts tested (2, 3, 5, 10)\n- ✅ All query types tested (AND, OR, mixed)\n- ✅ Both Diagon and Lucene results collected\n- ✅ Speedup calculated for each query\n- ✅ Target speedup ({{target_speedup}}x) met for majority of queries\n- ✅ WAND advantage demonstrated for OR queries\n- ✅ Scalability trend positive (speedup increases with complexity)\n- ✅ No crashes or errors\n- ✅ Results stable across iterations\n- ✅ Complete comparison report generated\n\n## Error Handling\n\n### Query Timeout\n```\n⚠️ Query timeout: [query]\nSystem: [Diagon/Lucene]\nLatency: >[timeout]ms\nAction: Flag as performance issue, investigate\n```\n\n### Speedup Below Target\n```\n❌ Below target: [query]\nSpeedup: [x.xx]x\nTarget: {{target_speedup}}x\nGap: [x.xx]x\nAction: Priority optimization candidate\n```\n\n### Lucene Data Missing\n```\n⚠️ No Lucene baseline data for: [query]\nAction: Use estimated baseline or run Lucene benchmark\n```\n\n### Incorrect Results\n```\n❌ Hit count mismatch: [query]\nLucene hits: [n]\nDiagon hits: [m]\nAction: Verify query correctness, investigate\n```\n\n## Use Cases\n\n### Optimization Validation\n- Before: Baseline multi-term comparison\n- Optimize: WAND, query planning, etc.\n- After: Re-compare\n- Validate: Speedup improvement\n\n### Target Validation\n- Goal: Verify 3-10x speedup for multi-term queries\n- Measure: Actual speedup per query type\n- Report: Achievement rate vs target\n\n### WAND Effectiveness\n- Test: OR queries with different term counts\n- Compare: Diagon (with WAND) vs Lucene (without block-max WAND)\n- Validate: Super-linear speedup increase\n\n### Competitive Analysis\n- Compare: Diagon vs Lucene for common query patterns\n- Identify: Where Diagon excels\n- Market: Highlight performance advantages\n\nNow execute the multi-term query comparison benchmark following these steps."
